= Data Mid-Bootcamp Project
:stylesheet: boot-darkly.css
:linkcss: boot-darkly.css
:image-url-ironhack: https://user-images.githubusercontent.com/23629340/40541063-a07a0a8a-601a-11e8-91b5-2f13e4e6b441.png
:my-name: Jorge Castro DAPT NOV2021
:description:
//:fn-xxx: Add the explanation foot note here bla bla
:url-dataset: https://www.kaggle.com/sid321axn/beijing-multisite-airquality-data-set
:url-dataset2: https://archive.ics.uci.edu/ml/datasets/Beijing+Multi-Site+Air-Quality+Data
:url-api: https://www.weatherapi.com/docs/
:url-influx: https://www.influxdata.com
:url-grafana: https://grafana.com/
:toc:
:toc-title: 
:toc-placement!:
:toclevels: 5
ifdef::env-github[]
:sectnums:
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
:experimental:
:table-caption!:
:example-caption!:
:figure-caption!:
:idprefix:
:idseparator: -
:linkattrs:
:fontawesome-ref: http://fortawesome.github.io/Font-Awesome
:icon-inline: {user-ref}/#inline-icons
:icon-attribute: {user-ref}/#size-rotate-and-flip
:video-ref: {user-ref}/#video
:checklist-ref: {user-ref}/#checklists
:list-marker: {user-ref}/#custom-markers
:list-number: {user-ref}/#numbering-styles
:imagesdir-ref: {user-ref}/#imagesdir
:image-attributes: {user-ref}/#put-images-in-their-place
:toc-ref: {user-ref}/#table-of-contents
:para-ref: {user-ref}/#paragraph
:literal-ref: {user-ref}/#literal-text-and-blocks
:admon-ref: {user-ref}/#admonition
:bold-ref: {user-ref}/#bold-and-italic
:quote-ref: {user-ref}/#quotation-marks-and-apostrophes
:sub-ref: {user-ref}/#subscript-and-superscript
:mono-ref: {user-ref}/#monospace
:css-ref: {user-ref}/#custom-styling-with-attributes
:pass-ref: {user-ref}/#passthrough-macros
endif::[]
ifndef::env-github[]
:imagesdir: ./
endif::[]

image::{image-url-ironhack}[width=70]

{my-name}


                                                     
====
''''
====
toc::[]

{description}


= Build and deploy a Data Ingestion Pipeline Pull

== Objective

Build a platform to handle time series data (metrics and events) from IoT devices, store them on a database and visualize it on a dashboard.



== Data Sources

For this project I will use weather data, specifically Multi-Site Air-Quality Data:

=== Data set for historical data
{url-dataset}[Beijing Multi-Site Air-Quality Data Set (CSV files)]

{url-dataset2}[Beijing Multi-Site Air-Quality Data Set from the Machine Learning Repository]

=== External API for real-time data

{url-api}[Weather API]


====
''''
====
Technologies to be used:

* AWS EC2 linux instance
* Python
* Docker containers
** {url-influx}[InfluxDB (Open source Time series database)]
** {url-grafana}[Grafana (Open source Data visualization web tool)]


====
''''
====

== How the final product is going to look like

The first part is the database storing the data. For this I will be using InfluxDB which is a time series database and better suited to handle this type of data without too much overhead.

In InfluxDB we can build queries and visualize them there on an integrated graphical interface. However I will not be using InfluxDB to visualize the data as we cannot allow the stakeholders that will be consuming this data to have direct access to the database. 

image::https://user-images.githubusercontent.com/63274055/155841851-0e80a26f-431e-45a7-88f2-113ae0598fbf.gif[width=800]

The to visualize..   

image::https://user-images.githubusercontent.com/63274055/155845094-0c165537-ce41-4324-83d4-5d439743c28e.gif[width=800]
====
''''
====

== What I am going to build


The platform is going to have 2 parts:

* Ingestion of the CSV files
* Ingestion of the API json files



image::https://user-images.githubusercontent.com/63274055/155846581-3e8dd67a-1943-432e-9011-ab60ba348538.png[width=900]

* Part I:

. CSV files to be worked on which are the time series dataset

. Then I am going to create a Python ingestion program. This program is going to take the csv file,

. and is going to write it into the InfluxDB database, hosted as a Docker container. Once the data is in InfluxDB, (where the data and aggregations are stored) 

. then I can set up a dashboard in Grafana, also hosted in a Docker container and query the data from InfluxDB

. The "Client" is the pc of the stakeholders from which the Grafana UI will be accessed to the AWS EC2 instance with an URL

* Part II:

. Accesing the external Weather API

. and have a Python integration script which will query data from the Weather API and then write it to 

. the InfluxDB database 

.  Finlay the steps 4 and 5 repeat as in Part I.





xref:Lab-xxxx[Top Section]

xref:Last-section[Bottom section]

//bla bla blafootnote:[{fn-xxx}]
//`*_Answer:_*`

////
.Unordered list title
* gagagagagaga
** gagagatrtrtrzezeze
*** zreu fhjdf hdrfj 
*** hfbvbbvtrtrttrhc
* rtez uezrue rjek  

.Ordered list title
. rwieuzr skjdhf
.. weurthg kjhfdsk skhjdgf
. djhfgsk skjdhfgs 
.. lksjhfgkls ljdfhgkd
... kjhfks sldfkjsdlk




[,sql]
----
----



[NOTE]
====
A sample note admonition.
====
 
TIP: It works!
 
IMPORTANT: Asciidoctor is awesome, don't forget!
 
CAUTION: Don't forget to add the `...-caption` document attributes in the header of the document on GitHub.
 
WARNING: You have no reason not to use Asciidoctor.

bla bla bla the 1NF or first normal form.footnote:[{1nf}]Then wen bla bla


====
- [*] checked
- [x] also checked
- [ ] not checked
-     normal list item
====
[horizontal]
CPU:: The brain of the computer.
Hard drive:: Permanent storage for operating system and/or user files.
RAM:: Temporarily stores information the CPU uses during operation.






bold *constrained* & **un**constrained

italic _constrained_ & __un__constrained

bold italic *_constrained_* & **__un__**constrained

monospace `constrained` & ``un``constrained

monospace bold `*constrained*` & ``**un**``constrained

monospace italic `_constrained_` & ``__un__``constrained

monospace bold italic `*_constrained_*` & ``**__un__**``constrained

////
